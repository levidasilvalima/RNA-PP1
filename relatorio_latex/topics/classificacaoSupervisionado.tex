Uma tarefa de classificação que poderia ser usada é levar em consideração informações como: idade, comorbidades (diabetes, hipertensão), classificação (confirmado ou não) e a partir disso poder prever uma possível situação final para o individuo (recuperado ou óbito), para tanto pode-se utilizar algoritmos de aprendizado supervisionado como rede neural. Nesse contexto o atributo alvo para a rede neural seria 'conclusão' mostrando assim se o individuo se recuperou ou veio a óbito. Mas não basta apenas criar um modelo, treina-lo e por em pratica, é necessário avaliar a qualidade do modelo produzido e para isso há algumas métricas capazes de aferir tais características. Uma métrica que caberia a esse problema é o \textit{F1 Score} que é uma média harmônica entre precisão, ela é muito boa quando você possui um \textit{dataset} com classes desproporcionais (esse caso em particular é um desses), e o modelo não emite probabilidades (também se encaixa aqui). Obs: Isso não significa que não possa ser usada com modelos que emitem probabilidades, tudo depende do objetivo da tarefa de \textit{machine learning}.

\textit{Precision} também poderia ser usado nessa caso já que ele basicamente analisa o número de exemplos classificados como pertencentes a uma classe, que realmente são daquela classe (positivos verdadeiros) e divide pela soma entre este número, e o número de exemplos classificados nesta classe, mas que pertencem a outras (falsos positivos). O \textit{recall} que é bem similar ao que o \textit{precision} faz.

Para a validação dos dados pode-se utilizar métodos como \textit{Holdout}, \textit{Cross-Validation} e \textit{Leave-one-out} que permitem fazer a verificação do modelo de forma mais empírica.